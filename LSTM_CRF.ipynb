{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740c0a13",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM-CRF\n",
    "\n",
    "Implemented by following: \n",
    "- https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb\n",
    "\n",
    "- https://github.com/xuxingya/tf2crf/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NERcorpus import NERCorpus\n",
    "from utils.prediction_vis import print_labeled_tag_pred_example\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tf2crf import CRF, ModelWithCRFLoss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "230c0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../nlp_d2_data/\"\n",
    "corpus = NERCorpus()\n",
    "train_seq = corpus.read_sequence_list_csv(f\"{data_path}train_data_ner.csv\")\n",
    "test_seq = corpus.read_sequence_list_csv(f\"{data_path}test_data_ner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61a7878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD in word_dict? True\n",
      "PAD0 in word_dict? False\n"
     ]
    }
   ],
   "source": [
    "print(\"PAD in word_dict?\", \"PAD\" in corpus.word_dict)\n",
    "\n",
    "print(\"PAD0 in word_dict?\", \"PAD0\" in corpus.word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "233a8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PAD0 tag to corpus.word_dict and .tag_dict\n",
    "corpus.word_dict.add(\"PAD0\")\n",
    "corpus.tag_dict.add(\"PAD0\")\n",
    "\n",
    "words = list(corpus.word_dict.keys())\n",
    "tags = list(corpus.tag_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse dictionaries inside corpus class\n",
    "corpus.reverse_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda42247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_onehot(tag_seqs, corpus, num_tag, max_len):\n",
    "    # Find the max length to pad sequences\n",
    "    max_len = max(len(seq) for seq in tag_seqs)\n",
    "\n",
    "    # Pad the tag sequences with the padding index\n",
    "    padded_tag_seqs = pad_sequences(tag_seqs, maxlen=max_len, padding='post', value=corpus.tag_dict[\"PAD0\"])\n",
    "\n",
    "    # Convert to one-hot encoded format (shape: num_sequences x max_len x num_tag)\n",
    "    y_one_hot = to_categorical(padded_tag_seqs, num_classes=num_tag)\n",
    "\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93795be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_seq(seq, corpus, num_tag):\n",
    "    # Extract word and tag sequences from train_seq.seq_list\n",
    "    word_seqs = [seqi.x for seqi in seq.seq_list]\n",
    "    tag_seqs = [seqi.y for seqi in seq.seq_list]\n",
    "\n",
    "    # Pad sequences to max_len\n",
    "    sequence_lengths = [len(seq.x) for seq in train_seq.seq_list]\n",
    "    max_len = max(sequence_lengths)\n",
    "\n",
    "    X = pad_sequences(word_seqs, maxlen=max_len, padding='post', value=corpus.word_dict[\"PAD0\"])\n",
    "\n",
    "    # One hot encoding of tags\n",
    "    y = tag_onehot(tag_seqs, corpus, num_tag, max_len)\n",
    "\n",
    "    return X, y, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c48e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tag = len(corpus.tag_dict)\n",
    "X_train, y_train, max_len = format_seq(train_seq, corpus, num_tag)\n",
    "X_test, y_test, _ = format_seq(test_seq, corpus, num_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2449f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points passed in each iteration\n",
    "batch_size = 64 \n",
    "# Passes through entire dataset\n",
    "epochs = 8\n",
    "# Dimension of embedding vector\n",
    "embedding = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1306a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training input data :  (38366, 104)\n",
      "Size of training output data :  (38366, 104, 18)\n",
      "Size of testing input data :  (38367, 104)\n",
      "Size of testing output data :  (38367, 104, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training input data : \", X_train.shape)\n",
    "print(\"Size of training output data : \", np.array(y_train).shape)\n",
    "print(\"Size of testing input data : \", X_test.shape)\n",
    "print(\"Size of testing output data : \", np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba049a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(input_dim=len(words), output_dim=embedding, input_length=max_len, mask_zero=True)(input_layer)\n",
    "bilstm_layer = Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1))(embedding_layer)\n",
    "td_dense = TimeDistributed(Dense(50, activation=\"relu\"))(bilstm_layer)\n",
    "\n",
    "crf = CRF(units=num_tag +1)\n",
    "output_layer = crf(td_dense)\n",
    "\n",
    "base_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model = ModelWithCRFLoss(base_model, sparse_target=False, metric='accuracy')\n",
    "model.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820a2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 22:54:20.147162: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2025-06-13 22:54:20.147407: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "600/600 [==============================] - 127s 205ms/step - loss: 22.8968 - accuracy: 0.9443\n",
      "Epoch 2/8\n",
      "600/600 [==============================] - 128s 213ms/step - loss: 3.6747 - accuracy: 0.9898\n",
      "Epoch 3/8\n",
      "600/600 [==============================] - 129s 215ms/step - loss: 2.1984 - accuracy: 0.9934\n",
      "Epoch 4/8\n",
      "600/600 [==============================] - 129s 215ms/step - loss: 1.6830 - accuracy: 0.9946\n",
      "Epoch 5/8\n",
      "600/600 [==============================] - 131s 218ms/step - loss: 1.3715 - accuracy: 0.9954\n",
      "Epoch 6/8\n",
      "600/600 [==============================] - 133s 222ms/step - loss: 1.1572 - accuracy: 0.9960\n",
      "Epoch 7/8\n",
      "600/600 [==============================] - 135s 225ms/step - loss: 0.9927 - accuracy: 0.9964\n",
      "Epoch 8/8\n",
      "600/600 [==============================] - 136s 227ms/step - loss: 0.8529 - accuracy: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30127c160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb646c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred_tag_idxs = model.predict(X_test)\n",
    "y_test_tag_idxs = np.argmax(y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd17c4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is : 98.1%\n"
     ]
    }
   ],
   "source": [
    "# Flatten lists of lists into one long list (preserving order)\n",
    "y_test_flat = [tag for seq in y_pred_tag_idxs for tag in seq]\n",
    "y_pred_flat = [tag for seq in y_test_tag_idxs for tag in seq]\n",
    "\n",
    "f1_test = f1_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "print(f\"F1-score is : {f1_test:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True tags:\n",
      "Iranian/B-gpe officials/O say/O they/O expect/O to/O get/O access/O to/O sealed/O sensitive/O parts/O of/O the/O plant/O Wednesday/B-tim ,/O after/O an/O IAEA/B-org surveillance/O system/O begins/O functioning/O ./O\n",
      "\n",
      "Predicted tags:\n",
      "Iranian/B-gpe officials/O say/O they/O expect/O to/O get/O access/O to/O sealed/O sensitive/O parts/O of/O the/O plant/O Wednesday/B-tim ,/O after/O an/O IAEA/B-org surveillance/O system/O begins/O functioning/O ./O\n"
     ]
    }
   ],
   "source": [
    "print_labeled_tag_pred_example(X_test, y_test_tag_idxs, y_pred_tag_idxs, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "226535c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 23:54:37.500765: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/bilstm_crf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/bilstm_crf_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save base model\n",
    "model.save('models/bilstm_crf_model')\n",
    "\n",
    "# Save the corpus object\n",
    "with open(\"models/bilstm_crf_model_corpus.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model back:\n",
    "\n",
    "# import tensorflow as tf\n",
    "# lo = tf.keras.models.load_model('models/bilstm_crf_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quora_challenge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
